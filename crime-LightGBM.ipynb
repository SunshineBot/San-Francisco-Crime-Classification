{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as gbm\n",
    "import gensim\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to resample it, but it doesn't works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates  DayOfWeek PdDistrict                    Address  \\\n",
       "0  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "1  2015-05-13 23:53:00  Wednesday   NORTHERN         OAK ST / LAGUNA ST   \n",
       "2  2015-05-13 23:33:00  Wednesday   NORTHERN  VANNESS AV / GREENWICH ST   \n",
       "3  2015-05-13 23:30:00  Wednesday   NORTHERN   1500 Block of LOMBARD ST   \n",
       "4  2015-05-13 23:30:00  Wednesday       PARK  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DayOfWeek = (\n",
    "    'Monday',\n",
    "    'Tuesday',\n",
    "    'Wednesday',\n",
    "    'Thursday',\n",
    "    'Friday',\n",
    "    'Saturday',\n",
    "    'Sunday'\n",
    ")\n",
    "Add_dict = {}\n",
    "Category_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# def resample(data):\n",
    "#         w = {}\n",
    "#         # d =  pd.read_csv('./data/weight.csv')\n",
    "#         remove_list = []\n",
    "#         add_items = []\n",
    "#         for index, row in pd.read_csv('./data/weight.csv').iterrows():\n",
    "#             w[row[0]] = row[1]\n",
    "#         for index, row in data.iterrows():\n",
    "#             weight = w[row['Category']]\n",
    "#             if weight < 1:\n",
    "#                 if random.random() > weight:\n",
    "#                     remove_list.append(index)\n",
    "#             elif weight > 1:\n",
    "#                 add_items += [row] * int(weight)\n",
    "#         data.drop(remove_list, inplace=True)\n",
    "#         res = pd.concat([data, pd.DataFrame(add_items)], ignore_index=True, copy=False)\n",
    "#         return res\n",
    "    \n",
    "data = pd.read_csv('./crime/data/train.csv')\n",
    "test = pd.read_csv('./crime/data/test.csv')\n",
    "# data = resample(data)\n",
    "y=data.Category\n",
    "Category_encoder.fit(y)\n",
    "data.drop(['Category', 'Descript', 'Resolution'], axis=1, inplace=True)\n",
    "test_id = pd.DataFrame({\"Id\":test.Id})\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间特征\n",
    "这里看了一下各个时间点的犯罪统计。\n",
    "* 年：年份对犯罪数量没什么影响，除了2015年只有一半的时间导致犯罪数量锐减\n",
    "* 月：基本没有影响，大致稳定在65000~80000范围内\n",
    "* 日：除了1号稍多，其它日期比较平稳\n",
    "* 时：这个呈现出比较明显的特征，上午8时开始逐渐上升，两次顶峰出现在12点和18点，凌晨1点开始回落。\n",
    "* 分：这个特征异常明显，在整点时（分=0）的犯罪数量约占30%，半点时（分=30）的犯罪数量约占14%，在分=1和其它分钟数为5的倍数时，犯罪数量在15000~40000以内波动，远高于其它时间（4000~5000内波动），其中以15、45最高\n",
    "\n",
    "## 时间处理\n",
    "* 时：我们认为不同小时的犯罪类型应当是适合在一天的不同时段进行的犯罪，因此按时段分为有序的4类：1-7，8-12，13-18，19-24。但是事实说明这样处理效果不好，所以没有采用。\n",
    "* 分：我们认为分钟意味着是否有预谋，在整点进行的犯罪通常是有预谋的（分=1可能是因为时间误差或者动手延迟），非整点常常是即兴犯罪，因此分2类：整点（分=0，1，15，30，45），非整点（分=其它）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process date features\n",
    "min_feature_set = set((0, 1, 15, 30, 45))\n",
    "\n",
    "def day_transform(str):\n",
    "        return DayOfWeek.index(str)\n",
    "\n",
    "def process_date(x):\n",
    "        def f(str):\n",
    "            # year, month, date, hour, minute\n",
    "            date_list = list(map(lambda x: int(x), re.split('[ :-]', str)[0:5]))\n",
    "#             hour = date_list[3]\n",
    "#             if hour >= 1 and hour < 8:\n",
    "#                 date_list.append(0)\n",
    "#             elif hour >=8 and hour < 13:\n",
    "#                 date_list.append(1)\n",
    "#             elif hour >=13 and hour < 19:\n",
    "#                 date_list.append(2)\n",
    "#             else:\n",
    "#                 date_list.append(3)\n",
    "            date_list.append(0 if date_list[4] in min_feature_set else 1)\n",
    "            return date_list\n",
    "\n",
    "        l = []\n",
    "        for s in x.Dates:\n",
    "            l.append(f(s))\n",
    "        date_frame = pd.DataFrame(np.array(l),\n",
    "                                  columns=['year', 'month', 'date', 'hour', 'minute', 'minute_feature'])\n",
    "        date_frame.insert(5, 'DayOfWeek', x.DayOfWeek.apply(day_transform))\n",
    "        return date_frame\n",
    "#         x.drop(['Dates'], axis=1, inplace=True)\n",
    "#         return pd.concat([date_frame, x], axis=1, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>minute_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  date  hour  minute  DayOfWeek  minute_feature\n",
       "0  2015      5    13    23      53          2               1\n",
       "1  2015      5    13    23      53          2               1\n",
       "2  2015      5    13    23      33          2               1\n",
       "3  2015      5    13    23      30          2               0\n",
       "4  2015      5    13    23      30          2               0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_date = process_date(data)\n",
    "test_date = process_date(test)\n",
    "data_date.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.insert(len(data.columns), ['pd' + str(i) for i in range(1, 11)], [pd.get_dummies(data.PdDistrict)])\n",
    "data_dist = pd.get_dummies(data.PdDistrict)\n",
    "test_dist = pd.get_dummies(test.PdDistrict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_address(x, clean=True):\n",
    "    \"\"\"\n",
    "    这个函数最终没有使用。\n",
    "    \n",
    "    将数据集中的地址进行one-hot编码，对于出现次数小于100的地址，全部归入other。\n",
    "    若clean为True，表示用于训练集，会统计出现的地址，并计算编码\n",
    "    若clean为False，表示用于测试集，仅用之前统计的字典将地址编码，\n",
    "    未出现的地址认为是小概率地址，归入other\n",
    "    :param x: DataFrame\n",
    "    :param clean: 是否清除之前统计的数据\n",
    "    :return: 编码后的DataFrame\n",
    "    \"\"\"\n",
    "    global Add_dict\n",
    "\n",
    "    def pre(str):\n",
    "        global Add_dict\n",
    "        if str in Add_dict:\n",
    "            Add_dict[str] += 1\n",
    "        else:\n",
    "            Add_dict[str] = 0\n",
    "    \n",
    "    def trans2(str):\n",
    "        return str if str in address_set else 'others'\n",
    "\n",
    "    if clean:\n",
    "        Add_dict = {}\n",
    "        x.Address.apply(pre)\n",
    "        remove_list = []\n",
    "        for k, v in Add_dict.items():\n",
    "            if v < 100:\n",
    "                remove_list.append(k)\n",
    "        for k in remove_list:\n",
    "            Add_dict.pop(k)\n",
    "    address_set = tuple(Add_dict.keys())\n",
    "    x.Address = x.Address.apply(trans2)\n",
    "    return pd.get_dummies(x.Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720650570"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "将地址进行分词并训练成100维词向量\n",
    "'/'也作为一个单词进行训练\n",
    "\"\"\"\n",
    "word2vec_n = 100\n",
    "data_sentences = []\n",
    "for s in data.Address:\n",
    "    data_sentences.append(s.split(' '))\n",
    "# test_sentences = []\n",
    "for s in test.Address:\n",
    "    data_sentences.append(s.split(' '))\n",
    "data_model = gensim.models.Word2Vec(data_sentences, min_count=1, size=word2vec_n, workers=30)\n",
    "data_model.train(data_sentences, total_examples=len(data_sentences), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "将地址转换为词向量\n",
    "\"\"\"\n",
    "def address_transform(str):\n",
    "    vec=0\n",
    "    for s in str.split(' '):\n",
    "        vec+=data_model[s]\n",
    "    return vec\n",
    "data_addr_list = []\n",
    "test_addr_list = []\n",
    "for add in data.Address:\n",
    "    data_addr_list.append(address_transform(add))\n",
    "data_addr = pd.DataFrame(data_addr_list, columns=['addr_%d' % i for i in range(0, word2vec_n)])\n",
    "for add in test.Address:\n",
    "    test_addr_list.append(address_transform(add))\n",
    "test_addr = pd.DataFrame(test_addr_list, columns=['addr_%d' % i for i in range(0, word2vec_n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_addr_gmm(n=50):\n",
    "    \"\"\"处理Address词向量信息\n",
    "    使用高斯混合模型对地址的词向量进行聚类\n",
    "    \n",
    "    Args: \n",
    "        n: 聚类的类别数量\n",
    "    \"\"\"\n",
    "    addr_gmm = mixture.GaussianMixture(n_components=50, covariance_type='diag').fit(data_addr)\n",
    "    return pd.get_dummies(pd.Series(addr_gmm.predict(data_addr))), pd.get_dummies(pd.Series(addr_gmm.predict(test_addr)))\n",
    "data_addr_gmm, test_addr_gmm = process_addr_gmm(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   130  131  132  133  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   134  135  136  137  138  139  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_loc(n):\n",
    "    \"\"\"处理经纬度信息\n",
    "    使用高斯混合模型进行聚类\n",
    "    \n",
    "    Args: \n",
    "        n: 聚类的类别数量\n",
    "    \"\"\"\n",
    "    gmm = mixture.GaussianMixture(n_components=n, covariance_type='diag').fit(data[['X', 'Y']])\n",
    "    return pd.get_dummies(pd.Series(gmm.predict(data[['X', 'Y']]))), pd.get_dummies(pd.Series(gmm.predict(test[['X', 'Y']])))\n",
    "data_loc, test_loc = process_loc(140)\n",
    "data_loc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>minute_feature</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_90</th>\n",
       "      <th>addr_91</th>\n",
       "      <th>addr_92</th>\n",
       "      <th>addr_93</th>\n",
       "      <th>addr_94</th>\n",
       "      <th>addr_95</th>\n",
       "      <th>addr_96</th>\n",
       "      <th>addr_97</th>\n",
       "      <th>addr_98</th>\n",
       "      <th>addr_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.546991</td>\n",
       "      <td>-2.134894</td>\n",
       "      <td>-1.915281</td>\n",
       "      <td>2.306646</td>\n",
       "      <td>1.333409</td>\n",
       "      <td>-2.913253</td>\n",
       "      <td>2.142856</td>\n",
       "      <td>-0.980920</td>\n",
       "      <td>-3.165184</td>\n",
       "      <td>5.596323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.546991</td>\n",
       "      <td>-2.134894</td>\n",
       "      <td>-1.915281</td>\n",
       "      <td>2.306646</td>\n",
       "      <td>1.333409</td>\n",
       "      <td>-2.913253</td>\n",
       "      <td>2.142856</td>\n",
       "      <td>-0.980920</td>\n",
       "      <td>-3.165184</td>\n",
       "      <td>5.596323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123078</td>\n",
       "      <td>-0.874606</td>\n",
       "      <td>-1.186695</td>\n",
       "      <td>-2.600078</td>\n",
       "      <td>-1.450801</td>\n",
       "      <td>1.797596</td>\n",
       "      <td>2.760073</td>\n",
       "      <td>1.360794</td>\n",
       "      <td>-2.979972</td>\n",
       "      <td>4.049474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092991</td>\n",
       "      <td>-2.009022</td>\n",
       "      <td>2.491399</td>\n",
       "      <td>-1.745062</td>\n",
       "      <td>0.811430</td>\n",
       "      <td>3.055635</td>\n",
       "      <td>-0.426461</td>\n",
       "      <td>-1.896576</td>\n",
       "      <td>0.339530</td>\n",
       "      <td>-2.595366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056252</td>\n",
       "      <td>-2.127862</td>\n",
       "      <td>2.573607</td>\n",
       "      <td>2.720907</td>\n",
       "      <td>0.431179</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>2.623312</td>\n",
       "      <td>-1.407373</td>\n",
       "      <td>2.989151</td>\n",
       "      <td>-0.091687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  date  hour  minute  DayOfWeek  minute_feature  0  1  2  \\\n",
       "0  2015      5    13    23      53          2               1  0  0  0   \n",
       "1  2015      5    13    23      53          2               1  0  0  0   \n",
       "2  2015      5    13    23      33          2               1  0  0  0   \n",
       "3  2015      5    13    23      30          2               0  0  0  0   \n",
       "4  2015      5    13    23      30          2               0  0  0  0   \n",
       "\n",
       "     ...      addr_90   addr_91   addr_92   addr_93   addr_94   addr_95  \\\n",
       "0    ...    -3.546991 -2.134894 -1.915281  2.306646  1.333409 -2.913253   \n",
       "1    ...    -3.546991 -2.134894 -1.915281  2.306646  1.333409 -2.913253   \n",
       "2    ...     0.123078 -0.874606 -1.186695 -2.600078 -1.450801  1.797596   \n",
       "3    ...     1.092991 -2.009022  2.491399 -1.745062  0.811430  3.055635   \n",
       "4    ...     1.056252 -2.127862  2.573607  2.720907  0.431179  0.781310   \n",
       "\n",
       "    addr_96   addr_97   addr_98   addr_99  \n",
       "0  2.142856 -0.980920 -3.165184  5.596323  \n",
       "1  2.142856 -0.980920 -3.165184  5.596323  \n",
       "2  2.760073  1.360794 -2.979972  4.049474  \n",
       "3 -0.426461 -1.896576  0.339530 -2.595366  \n",
       "4  2.623312 -1.407373  2.989151 -0.091687  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.concat([data_date, data_loc, data_dist, data_addr], axis=1, copy=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- boosting_type (string, optional (default=\"gbdt\")) – ‘gbdt’, traditional Gradient Boosting Decision Tree. ‘dart’, Dropouts meet Multiple Additive Regression Trees. ‘goss’, Gradient-based One-Side Sampling. ‘rf’, Random Forest.\n",
    "- num_leaves (int, optional (default=31)) – Maximum tree leaves for base learners.\n",
    "- max_depth (int, optional (default=-1)) – Maximum tree depth for base learners, -1 means no limit.\n",
    "- learning_rate (float, optional (default=0.1)) – Boosting learning rate.\n",
    "- n_estimators (int, optional (default=100)) – Number of boosted trees to fit.\n",
    "- subsample_for_bin (int, optional (default=50000)) – Number of samples for constructing bins.\n",
    "- objective (string, callable or None, optional (default=None)) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below). default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.\n",
    "- class_weight (dict, 'balanced' or None, optional (default=None)) – Weights associated with classes in the form {class_label: weight}. Use this parameter only for multi-class classification task; for binary classification task you may use is_unbalance or scale_pos_weight parameters. The ‘balanced’ mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). If None, all classes are supposed to have weight one. Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "- min_split_gain (float, optional (default=0.)) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "- min_child_weight (float, optional (default=1e-3)) – Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
    "- min_child_samples (int, optional (default=20)) – Minimum number of data need in a child(leaf).\n",
    "- subsample (float, optional (default=1.)) – Subsample ratio of the training instance.\n",
    "- subsample_freq (int, optional (default=1)) – Frequence of subsample, <=0 means no enable.\n",
    "- colsample_bytree (float, optional (default=1.)) – Subsample ratio of columns when constructing each tree.\n",
    "- reg_alpha (float, optional (default=0.)) – L1 regularization term on weights.\n",
    "- reg_lambda (float, optional (default=0.)) – L2 regularization term on weights.\n",
    "- random_state (int or None, optional (default=None)) – Random number seed. Will use default seeds in c++ code if set to None.\n",
    "- n_jobs (int, optional (default=-1)) – Number of parallel threads.\n",
    "- silent (bool, optional (default=True)) – Whether to print messages while running boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.84409965802\n",
      "test: 2.22612029068 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.05, max_depth=8, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=350,\n",
       "        n_jobs=32, num_leaves=128, objective='multiclass',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=0.6, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(submit=False):\n",
    "    \"\"\"训练函数\n",
    "    通过设定好的参数进行训练\n",
    "    \n",
    "    Args:\n",
    "        submit: 表示是否使用训练集部数据训练模型。如果False，将训练集数据拆分为训练集（70%）和测试集（30%），\n",
    "        训练完成后分别测试模型在训练集和测试集上的表现；如果True，将训练集数据用于训练模型，输出模型在训练集上的表现，\n",
    "        然后使用kaggle测试集进行预测并保存预测结果用于提交。\n",
    "    \"\"\"\n",
    "    param = dict(max_depth=8, \n",
    "                 n_estimators=350, \n",
    "                 n_jobs=32, \n",
    "                 objective='multiclass', \n",
    "                 learning_rate=0.05, \n",
    "                 subsample=0.6, \n",
    "                 num_leaves=128)\n",
    "    \n",
    "    if submit:\n",
    "        X_train = pd.concat([data_date, data_loc, data_dist, data_addr], axis=1, copy=False)\n",
    "        y_train = Category_encoder.transform(y)\n",
    "        X_test = pd.concat([test_date, test_loc, test_dist, test_addr], axis=1, copy=False)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            pd.concat([data_date, data_loc, data_dist, data_addr], axis=1, copy=False), Category_encoder.transform(y), \n",
    "            test_size=0.3, random_state=0)\n",
    "\n",
    "    classifier = gbm.LGBMClassifier(**param)\n",
    "    classifier.fit(X_train, y_train, eval_metric='mlogloss')\n",
    "\n",
    "    result_train = pd.DataFrame(classifier.predict_proba(X_train))\n",
    "    result_test = pd.DataFrame(classifier.predict_proba(X_test))\n",
    "    \n",
    "    print('train:', log_loss(y_train, result_train))\n",
    "    if submit:\n",
    "        prefix=''\n",
    "        for k, v in  param.items():\n",
    "            prefix += '%s=%s.' % (k, str(v))\n",
    "        filepath = './crime/%scsv' % prefix\n",
    "        result = pd.DataFrame(result_train)\n",
    "        result_test.insert(0, 'Id', test.Id)\n",
    "        result_test.columns = result_test.columns.map(lambda m: Category_encoder.inverse_transform(m) if isinstance(m, int) else m)\n",
    "        result_test.to_csv(filepath, index=False)\n",
    "        print('Finished saving files. Filename:\\n' + filepath)\n",
    "    else:\n",
    "        print('test:', log_loss(y_test, result_test), '\\n')\n",
    "    return classifier\n",
    "\n",
    "train(submit=False)\n",
    "# classifier = train(submit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## xgboost:\n",
    "------------------------------\n",
    "### 最开始调的参数，但是并不适用于LightGBM\n",
    "xgboost.gmm=39.date=hour-minute-featured-with-DayOfWeek.loc=one-hot.dist=yes.addr=no.max_depth=8.n_estimators=100\n",
    "xgboost.gmm=39.date=DayOfWeek.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50 - train: 2.34525, test:2.42062\n",
    "xgboost.gmm=39.date=minute-featured-DayOfWeek.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50 - train: 2.3399, test: 2.4182\n",
    "xgboost.gmm=39.date=hour-featured-DayOfWeek.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50 - train:2.34595, test: 2.42104\n",
    "\n",
    "\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50 —— test:2.395\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=100 —— train: 2.278, test: 2.40\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50,subsample=0.5 —— train:2.36300, test:2.43554\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50,subsample=0.6 —— train:2.36127, test:2.43443\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50,subsample=0.7 —— train:2.3598, test:2.4346\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50,subsample=0.8 —— train:2.3601, test:2.4345\n",
    "xgboost.gmm=20.loc=one-hot.dist=one-hot.addr=no.max_depth=8.n_estimators=50,subsample=0.9 —— train:2.3605, test:2.4347\n",
    "\n",
    "### learning_rate = 0.1\n",
    "\n",
    "###### n_estimators: 50\n",
    "- train: 2.3475846850753084\n",
    "- test: 2.4300819496329393 \n",
    "\n",
    "###### n_estimators: 100\n",
    "- train: 2.2493114099258396\n",
    "- test: 2.3980333707882386 \n",
    "\n",
    "###### n_estimators: 150\n",
    "- train: 2.183500019381262\n",
    "- test: 2.3947450429680432 \n",
    "\n",
    "###### n_estimators: 200\n",
    "- train: 2.124935285254291\n",
    "- test: 2.3954496446712015 \n",
    "\n",
    "###### n_estimators: 250\n",
    "- train: 2.073948376885028\n",
    "- test: 2.398131535806666 \n",
    "\n",
    "###### max_depth=8, n_estimators=300, gamma=0.1:\n",
    "- train: 2.0262884178248872\n",
    "- test: 2.401822482656742 \n",
    "\n",
    "###### max_depth=6, n_estimators=300, gamma=0.1:\n",
    "- train: 2.25023725734\n",
    "- test: 2.39739200022 \n",
    "(学习能力明显下降，泛化能力明显上升）\n",
    "\n",
    "###### max_depth=8, n_estimators=300, gamma=0.1, min_child_weight=100:\n",
    "- train: 2.31327214908\n",
    "- test: 2.3994496945 \n",
    "（emmm泛化能力时提升了，但是这学习能力也下降了啊，最后测试集上的效果反而不好= =）\n",
    "\n",
    "## LGBM:\n",
    "----------------------------------------\n",
    "### learning_rate=0.1, num_leaves=31\n",
    "\n",
    "###### n_estimators=50\n",
    "- train: 2.422454054660593\n",
    "- test: 2.4404583378122604\n",
    "\n",
    "###### n_estimators=100\n",
    "- train: 2.3692381371383378\n",
    "- test: 2.4061435863370733\n",
    "\n",
    "###### n_estimators=150\n",
    "- train: 2.344883461603974\n",
    "- test: 2.4011314814512312\n",
    "\n",
    "###### n_estimators=200\n",
    "- train: 2.3248051741150637\n",
    "- test: 2.3993401253740334\n",
    "\n",
    "###### n_estimators=250\n",
    "- train: 2.3067374466734663\n",
    "- test: 2.398465633267535\n",
    "\n",
    "###### n_estimators=300\n",
    "- train: 2.290042564420303\n",
    "- test: 2.397985343171034\n",
    "\n",
    "###### n_estimators=350\n",
    "- train: 2.274443265517788\n",
    "- test: 2.3979380054115764\n",
    "\n",
    "### n_estimators=300, learning_rate=0.1, num_leaves=31\n",
    "\n",
    "###### number of components :  20\n",
    "* train: 2.2896706778032496\n",
    "*  test: 2.397423002843296\n",
    "\n",
    "###### number of components :  30\n",
    "* train: 2.282489219935824\n",
    "*  test: 2.388900244514006\n",
    "\n",
    "###### number of components :  40\n",
    "* train: 2.2792566711136835\n",
    "*  test: 2.385515245018877\n",
    "\n",
    "###### number of components :  50\n",
    "* train: 2.2648347392932076\n",
    "*  test: 2.371450279541818\n",
    "\n",
    "###### number of components :  60\n",
    "* train: 2.2651821271942696\n",
    "*  test: 2.370866385085879\n",
    "\n",
    "###### number of components :  70\n",
    "* train: 2.2653701804662734\n",
    "*  test: 2.3699399112568265\n",
    "\n",
    "###### number of components :  80\n",
    "* train: 2.263639326249622\n",
    "*  test: 2.368659649500926\n",
    "\n",
    "###### number of components :  90\n",
    "* train: 2.256510999107492\n",
    "*  test: 2.3603235176030766\n",
    "\n",
    "###### number of components :  100\n",
    "* train: 2.2609116781735126\n",
    "*  test: 2.363845173790893\n",
    "\n",
    "###### number of components :  110\n",
    "* train: 2.257224577635038\n",
    "*  test: 2.3595274867252343\n",
    "\n",
    "###### number of components :  120\n",
    "* train: 2.2519685240667475\n",
    "*  test: 2.3538891635210915\n",
    "\n",
    "### n_estimators=300, learning_rate=0.1, num_leaves=128\n",
    "\n",
    "###### number of components :  110\n",
    "- train: 2.147998594707557\n",
    "-  test: 2.3535705137712695\n",
    "\n",
    "###### number of components :  120\n",
    "- train: 2.1507204445765296\n",
    "-  test: 2.351659633317391\n",
    "\n",
    "###### number of components :  130\n",
    "- train: 2.1537820299763353\n",
    "-  test: 2.350372574069103\n",
    "\n",
    "###### number of components :  140\n",
    "- train: 2.1544479960148397\n",
    "-  test: 2.348725349761922\n",
    "\n",
    "###### number of components :  150\n",
    "- train: 2.16507444560338\n",
    "-  test: 2.35556314010956\n",
    "\n",
    "###### number of components :  160\n",
    "- train: 2.167476377354809\n",
    "-  test: 2.356295454033946\n",
    "\n",
    "##### submit:\n",
    "- train: 2.16489928137\n",
    "- test:2.36164\n",
    "\n",
    "parameters\n",
    "- max_depth=8, \n",
    "- n_estimators=350, \n",
    "- n_jobs=32, \n",
    "- objective='multiclass', \n",
    "- learning_rate=0.1, \n",
    "- subsample=0.6, \n",
    "- num_leaves=128\n",
    "\n",
    "##### submit\n",
    "- train: 2.24521060034\n",
    "- test: 2.36079\n",
    "\n",
    "parameters\n",
    "- max_depth=8, \n",
    "- n_estimators=350, \n",
    "- n_jobs=32, \n",
    "- objective='multiclass', \n",
    "- learning_rate=0.05, \n",
    "- subsample=0.6, \n",
    "- num_leaves=128\n",
    "\n",
    "这个参数在训练集上的错误率比上一个明显上升，我都没提交，后来死马当活马医交了一下，居然还降低了。\n",
    "\n",
    "#### Tuning hyper-parameters for neg_log_loss\n",
    "- 预设参数：{'n_jobs': 32, 'subsample': 0.6, 'objective': 'multiclass', 'max_depth': 8}\n",
    "\n",
    "Best parameters set found on development set:\n",
    "\n",
    "- {'num_leaves': 128, 'learning_rate': 0.05, 'n_estimators': 350}\n",
    "\n",
    "num_leaves越大，学习能力提升明显，泛化能力下降也明显。\n",
    "learning_rate降低应该要同时增加n_estimators才行。\n",
    "先调整learning_rate和n_estimators，然后再调整num_leaves和泛化性能吧。\n",
    "\n",
    "Grid scores on development set:\n",
    "\n",
    "- train: -1.999 (+/-0.001), test: -2.428 (+/-0.002) for {'num_leaves': 128, 'learning_rate': 0.1, 'n_estimators': 350}\n",
    "- train: -1.969 (+/-0.001), test: -2.431 (+/-0.002) for {'num_leaves': 170, 'learning_rate': 0.1, 'n_estimators': 350}\n",
    "- train: -1.963 (+/-0.001), test: -2.432 (+/-0.002) for {'num_leaves': 200, 'learning_rate': 0.1, 'n_estimators': 350}\n",
    "- train: -1.959 (+/-0.001), test: -2.434 (+/-0.002) for {'num_leaves': 128, 'learning_rate': 0.1, 'n_estimators': 400}\n",
    "- train: -1.926 (+/-0.001), test: -2.438 (+/-0.002) for {'num_leaves': 170, 'learning_rate': 0.1, 'n_estimators': 400}\n",
    "- train: -1.920 (+/-0.001), test: -2.439 (+/-0.002) for {'num_leaves': 200, 'learning_rate': 0.1, 'n_estimators': 400}\n",
    "- train: -2.161 (+/-0.001), test: -2.406 (+/-0.001) for {'num_leaves': 128, 'learning_rate': 0.05, 'n_estimators': 350}\n",
    "- train: -2.141 (+/-0.000), test: -2.406 (+/-0.002) for {'num_leaves': 170, 'learning_rate': 0.05, 'n_estimators': 350}\n",
    "- train: -2.138 (+/-0.001), test: -2.406 (+/-0.002) for {'num_leaves': 200, 'learning_rate': 0.05, 'n_estimators': 350}\n",
    "- train: -2.134 (+/-0.001), test: -2.407 (+/-0.001) for {'num_leaves': 128, 'learning_rate': 0.05, 'n_estimators': 400}\n",
    "- train: -2.113 (+/-0.000), test: -2.408 (+/-0.002) for {'num_leaves': 170, 'learning_rate': 0.05, 'n_estimators': 400}\n",
    "- train: -2.108 (+/-0.001), test: -2.408 (+/-0.002) for {'num_leaves': 200, 'learning_rate': 0.05, 'n_estimators': 400}\n",
    "- train: -2.301 (+/-0.000), test: -2.413 (+/-0.001) for {'num_leaves': 128, 'learning_rate': 0.02, 'n_estimators': 350}\n",
    "- train: -2.290 (+/-0.000), test: -2.413 (+/-0.001) for {'num_leaves': 170, 'learning_rate': 0.02, 'n_estimators': 350}\n",
    "- train: -2.287 (+/-0.000), test: -2.412 (+/-0.001) for {'num_leaves': 200, 'learning_rate': 0.02, 'n_estimators': 350}\n",
    "- train: -2.283 (+/-0.000), test: -2.408 (+/-0.001) for {'num_leaves': 128, 'learning_rate': 0.02, 'n_estimators': 400}\n",
    "- train: -2.271 (+/-0.000), test: -2.408 (+/-0.001) for {'num_leaves': 170, 'learning_rate': 0.02, 'n_estimators': 400}\n",
    "- train: -2.268 (+/-0.000), test: -2.408 (+/-0.001) for {'num_leaves': 200, 'learning_rate': 0.02, 'n_estimators': 400}\n",
    "\n",
    "\n",
    "#### Tuning hyper-parameters for neg_log_loss\n",
    "- min_child_samples=100 用来抑制过拟合，不知道效果如何（原值为10）\n",
    "- 预设参数：{'min_child_samples': 100, 'n_jobs': 32, 'num_leaves': 128, 'subsample': 0.6, 'objective': 'multiclass', 'max_depth': 8}\n",
    "\n",
    "Best parameters set found on development set:\n",
    "- {'learning_rate': 0.01, 'n_estimators': 400}\n",
    "\n",
    "Grid scores on development set:\n",
    "- train: -2.060 (+/-0.031), test: -7.202 (+/-3.426) for {'learning_rate': 0.1, 'n_estimators': 400}\n",
    "- train: -2.041 (+/-0.031), test: -7.364 (+/-3.457) for {'learning_rate': 0.1, 'n_estimators': 450}\n",
    "- train: -2.022 (+/-0.031), test: -7.487 (+/-3.491) for {'learning_rate': 0.1, 'n_estimators': 500}\n",
    "- train: -2.005 (+/-0.031), test: -7.585 (+/-3.520) for {'learning_rate': 0.1, 'n_estimators': 550}\n",
    "- train: -1.989 (+/-0.031), test: -7.710 (+/-3.553) for {'learning_rate': 0.1, 'n_estimators': 600}\n",
    "- train: -1.973 (+/-0.032), test: -7.806 (+/-3.557) for {'learning_rate': 0.1, 'n_estimators': 650}\n",
    "- train: -2.150 (+/-0.028), test: -6.296 (+/-3.192) for {'learning_rate': 0.05, 'n_estimators': 400}\n",
    "- train: -2.137 (+/-0.029), test: -6.439 (+/-3.276) for {'learning_rate': 0.05, 'n_estimators': 450}\n",
    "- train: -2.124 (+/-0.029), test: -6.575 (+/-3.336) for {'learning_rate': 0.05, 'n_estimators': 500}\n",
    "- train: -2.112 (+/-0.030), test: -6.678 (+/-3.364) for {'learning_rate': 0.05, 'n_estimators': 550}\n",
    "- train: -2.101 (+/-0.030), test: -6.790 (+/-3.391) for {'learning_rate': 0.05, 'n_estimators': 600}\n",
    "- train: -2.089 (+/-0.030), test: -6.882 (+/-3.408) for {'learning_rate': 0.05, 'n_estimators': 650}\n",
    "- train: -2.231 (+/-0.021), test: -5.339 (+/-2.646) for {'learning_rate': 0.02, 'n_estimators': 400}\n",
    "- train: -2.221 (+/-0.022), test: -5.462 (+/-2.738) for {'learning_rate': 0.02, 'n_estimators': 450}\n",
    "- train: -2.212 (+/-0.023), test: -5.567 (+/-2.847) for {'learning_rate': 0.02, 'n_estimators': 500}\n",
    "- train: -2.204 (+/-0.023), test: -5.651 (+/-2.908) for {'learning_rate': 0.02, 'n_estimators': 550}\n",
    "- train: -2.197 (+/-0.024), test: -5.736 (+/-2.966) for {'learning_rate': 0.02, 'n_estimators': 600}\n",
    "- train: -2.190 (+/-0.025), test: -5.820 (+/-3.002) for {'learning_rate': 0.02, 'n_estimators': 650}\n",
    "- train: -2.322 (+/-0.014), test: -4.514 (+/-1.548) for {'learning_rate': 0.01, 'n_estimators': 400}\n",
    "- train: -2.301 (+/-0.016), test: -4.645 (+/-1.743) for {'learning_rate': 0.01, 'n_estimators': 450}\n",
    "- train: -2.285 (+/-0.016), test: -4.768 (+/-1.920) for {'learning_rate': 0.01, 'n_estimators': 500}\n",
    "- train: -2.272 (+/-0.017), test: -4.883 (+/-2.079) for {'learning_rate': 0.01, 'n_estimators': 550}\n",
    "- train: -2.261 (+/-0.018), test: -4.992 (+/-2.225) for {'learning_rate': 0.01, 'n_estimators': 600}\n",
    "- train: -2.252 (+/-0.019), test: -5.097 (+/-2.363) for {'learning_rate': 0.01, 'n_estimators': 650}\n",
    "\n",
    "summary\n",
    "- min_child_samples严重降低了模型的泛化性能（为什么？）\n",
    "- 随着n_estimators的提升，泛化性能越来越低，降低learning_rate可以提升泛化性能，但是降低了拟合能力。\n",
    "- 可能是收到min_child_samples的影响，提高n_estimators并没有效果。\n",
    "- 建议测试：learning_rate=0.01, n_estimators=[350, 400, 450, 500], num_leaves=[128, 170, 200]\n",
    "- min_child_samples=[10, 20]吧,玩不起\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
